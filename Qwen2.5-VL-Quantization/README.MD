# 说明

1. 下载llm-compressor的源码。
2. 安装llm-compressor将examples文件夹里面的文件拷贝到对应目录下，执行对应的指令脚本即可。
3. 在server修改对应参数启动部署。
4. 使用vllm_inference.py进行推理测试。